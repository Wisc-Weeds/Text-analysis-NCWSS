---
title: "NCWSS-abstract"
author: "Maxwel Coura Oliveira"
date: "10/8/2020"
output: html_document
---


```{r include=FALSE}
library(ggwordcloud)
library(textreadr)
library(readr)
library(rvest)
library(downloader)
library(tidyverse)
library(tidytext)
library(pdftools)
library(dplyr)
library(wordcloud)
library(topicmodels)
library(xml2)
library(DescTools)
library(tm)
library(stringr)
library(rcorpora)
library(genius)
```


```{r}
# this code section will take long (~3 min) to run. 
clean_corpus <- function(corpus){
  corpus <- tm_map(corpus, removePunctuation) # remove punctuation
  corpus <- tm_map(corpus, content_transformer(tolower)) # remove punctuation
  corpus <- tm_map(corpus, removeNumbers) # remove numbers
  corpus <- tm_map(corpus, removeWords, stopwords_en) # remove stop words
  corpus <- tm_map(corpus, removeWords, stopwords_en) # remove stop words
  corpus <- tm_map(corpus, removeWords, stopwords_first) # remove stop words 
  corpus <- tm_map(corpus, removeWords, stopwords_last) # remove stop words
  corpus <- tm_map(corpus, removeWords, stopwords_countries) # remove stop words
  corpus <- tm_map(corpus, removeWords, stopwords_state) # remove stop words
  corpus <- tm_map(corpus, removeWords, stopwords_capitals ) # remove stop words  
  corpus
}
```



#2002

```{r}
co2002 <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/cereals2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
cs2002 <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/corn2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
met2002 <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/equipment2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
ext2002 <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/extension2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
for2002 <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/forage2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
phy2002 <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/physiology2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
turf2002 <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/industrial2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
soil2002 <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/soil2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
soy2002 <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/soybeans2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
hort2002 <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/sugarbeets2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
eco2002 <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/ecology2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
app2002 <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/applicsymposium2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
res2002 <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/glysymp2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
shi2002 <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/weedshiftsymp2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 



nc_2002 <- rbind(co2002, cs2002, met2002, ext2002, for2002, phy2002, soil2002, 
                 soy2002, turf2002, hort2002, eco2002, app2002, res2002, shi2002)
```


```{r warning=FALSE, include=FALSE}
titledm_02 <- data.frame() # as data frame

for (i in 1:length(nc_2002)) {
  print(i)
  titlelines <- data.frame(names = nc_2002[[i]])
  titledm_02 <- bind_rows(titledm_02, titlelines)
} 
```

```{r}
titledm_02$names <- gsub("2,4-D" , "twofourd" , titledm_02$names)
```

```{r}
title_tokens_02 <- titledm_02 %>%
  unnest_tokens(words, names)
```


```{r eval=FALSE, include=FALSE}
authors <- read_html("http://ncwss.org/proceed/2002/Proc2002/abstracts/author2.htm") %>% 
  html_nodes(xpath = "/html/body/p[.]") %>%
  html_text() 
authors <- c(authors)
authors <- data_frame(authors)
#tokerization
authors_tokens <- authors %>%
  unnest_tokens(words, authors)
```


```{r }
title_tokens_02 <- anti_join(title_tokens_02, stop_wssaprogram_words_tokens, by = "words") 
title_tokens_02 <- anti_join(title_tokens_02, stopwords_tokens, by = "words") 
title_tokens_02 <- anti_join(title_tokens_02, authors_tokens, by = "words") 
```


```{r}
title_source_02 <- VectorSource(title_tokens_02$words)
title_corpus_02 <- VCorpus(title_source_02)
```

```{r}
title_corpus_02 <- clean_corpus(title_corpus_02)
```

```{r}
title_dtm_02 <- TermDocumentMatrix(title_corpus_02)
title_matrix_02 <- as.matrix(title_dtm_02)
title_v_02 <- sort(rowSums(title_matrix_02), decreasing=TRUE)
title_dt_02 <- data.frame(word = names(title_v_02),freq=title_v_02)
```

```{r}
title_dt_02$word <- gsub("twofourd" , "2,4-D" , title_dt_02$word)
```

```{r fig.cap= "Most frequent words (n=30+) that appeared in the WSSA/WSWS oral and poster presentation titles."}
title_dt_02 %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,150) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words02 <- title_dt_02  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2002")
```




```{r} 
# need to stop footnotes' word

pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt_02$word, freq = title_dt_02$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```













#2003

```{r}
co2003 <- read_html("http://ncwss.org/proceed/2003/Proc03/abstracts/Cereals%20and%20Oilseeds.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
cs2003 <- read_html("http://ncwss.org/proceed/2003/Proc03/abstracts/Corn%20and%20Sorghum.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
met2003 <- read_html("http://ncwss.org/proceed/2003/Proc03/abstracts/Equipment%20and%20Application.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
ext2003 <- read_html("http://ncwss.org/proceed/2003/Proc03/abstracts/Extension.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
for2003 <- read_html("http://ncwss.org/proceed/2003/Proc03/abstracts/Forages%20and%20Range.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
phy2003 <- read_html("http://ncwss.org/proceed/2003/Proc03/abstracts/Herbicide%20Phy.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
soil2003 <- read_html("http://ncwss.org/proceed/2003/Proc03/abstracts/Soil%20and%20Environment.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
soy2003 <- read_html("http://ncwss.org/proceed/2003/Proc03/abstracts/Soybean.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
hort2003 <- read_html("http://ncwss.org/proceed/2003/Proc03/abstracts/Sugarbeet,%20hort,%20ornamental.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
eco2003 <- read_html("http://ncwss.org/proceed/2003/Proc03/abstracts/weed%20ecology.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
sym22003 <- read_html("http://ncwss.org/proceed/2003/Proc03/abstracts/symposia.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 



nc_2003 <- rbind(co2003, cs2003, met2003, ext2003, for2003, phy2003, soil2003, 
                 soy2003, hort2003, eco2003, sym22003)
```

```{r warning=FALSE, include=FALSE}
titledm_03 <- data.frame() # as data frame

for (i in 1:length(nc_2003)) {
  print(i)
  titlelines <- data.frame(names = nc_2003[[i]])
  titledm_03 <- bind_rows(titledm_03, titlelines)
} 
```

```{r}
titledm_03$names <- gsub("2,4-D" , "twofourd" , titledm_03$names)
```

```{r}
title_tokens_03 <- titledm_03 %>%
  unnest_tokens(words, names)
```


```{r eval=FALSE, include=FALSE}
authors_03 <- read_html("http://ncwss.org/proceed/2003/Proc03/abstracts/author%20index.htm") %>% 
  html_nodes(xpath = "/html/body/ilayer/table[2]") %>%
  html_text() 
authors_03 <- c(authors_03)
authors_03 <- data_frame(authors_03)
#tokerization
authors_tokens_03 <- authors_03 %>%
  unnest_tokens(words, authors_03)
```



```{r }
title_tokens_03 <- anti_join(title_tokens_03, stop_wssaprogram_words_tokens, by = "words") 
title_tokens_03 <- anti_join(title_tokens_03, stopwords_tokens, by = "words") 
title_tokens_03 <- anti_join(title_tokens_03, authors_tokens, by = "words") 
```




```{r}
title_source_03 <- VectorSource(title_tokens_03$words)
title_corpus_03 <- VCorpus(title_source_03)
```


```{r}
title_corpus_03 <- clean_corpus(title_corpus_03)
```

```{r}
title_dtm_03 <- TermDocumentMatrix(title_corpus_03)
title_matrix_03 <- as.matrix(title_dtm_03)
title_v_03 <- sort(rowSums(title_matrix_03), decreasing=TRUE)
title_dt_03 <- data.frame(word = names(title_v_03),freq=title_v_03)
```

```{r}
title_dt_03$word <- gsub("twofourd" , "2,4-D" , title_dt_03$word)
```

```{r fig.cap= "Most frequent words (n=30+) that appeared in the WSSA/WSWS oral and poster presentation titles."}
title_dt_03 %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,150) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words03 <- title_dt_03  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2003")
```


```{r message=FALSE, warning=FALSE}
# need to stop footnotes' word

pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt_03$word, freq = title_dt_03$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```



# 2004


```{r}
co2004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/cereals2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
cs2004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/corn2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
met2004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/equipment2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
ext2004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/extension2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
for2004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/forage2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
phy2004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/physiology2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
tur2004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/industrial2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
inv2004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/invasives2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
soy2004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/soybean2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
hort2004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/sugarbeets2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
eco2004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/ecology2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
tur22004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/herbtolturf2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
iv22004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/invasives2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
seed2004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/seedbankdynam2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
sind2004 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/seedindustry2.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 


nc_2004 <- rbind(co2004, cs2004, met2004, ext2004, for2004, phy2004, tur2004, inv2004, 
                 soy2004, hort2004, eco2004, tur22004, iv22004, seed2004, sind2004)
```

```{r warning=FALSE, include=FALSE}
titledm_04 <- data.frame() # as data frame

for (i in 1:length(nc_2004)) {
  print(i)
  titlelines <- data.frame(names = nc_2004[[i]])
  titledm_04 <- bind_rows(titledm_04, titlelines)
} 
```

```{r}
titledm_04$names <- gsub("2,4-D" , "twofourd" , titledm_04$names)
```


```{r}
title_tokens_04 <- titledm_04 %>%
  unnest_tokens(words, names)
```


```{r eval=FALSE, include=FALSE}
authors_04 <- read_html("http://ncwss.org/proceed/2004/proc04/abstracts/authors.htm") %>% 
  html_nodes(xpath = "//table[2]") %>%
  html_text() 
authors_04 <- c(authors_04)
authors_04 <- data_frame(authors_04)
#tokerization
authors_tokens_04 <- authors_04 %>%
  unnest_tokens(words, authors_04)
```


```{r }
title_tokens_04 <- anti_join(title_tokens_04, stop_wssaprogram_words_tokens, by = "words") 
title_tokens_04 <- anti_join(title_tokens_04, stopwords_tokens, by = "words") 
title_tokens_04 <- anti_join(title_tokens_04, authors_tokens, by = "words") 
```


```{r}
title_source_04 <- VectorSource(title_tokens_04$words)
title_corpus_04 <- VCorpus(title_source_04)
```



```{r}
title_corpus_04 <- clean_corpus(title_corpus_04)
```



```{r}
title_dtm_04 <- TermDocumentMatrix(title_corpus_04)
title_matrix_04 <- as.matrix(title_dtm_04)
title_v_04 <- sort(rowSums(title_matrix_04), decreasing=TRUE)
title_dt_04 <- data.frame(word = names(title_v_04),freq=title_v_04)
```


```{r}
title_dt_04$word <- gsub("twofourd" , "2,4-D" , title_dt_04$word)
```


```{r fig.cap= "Most frequent words (n=30+) that appeared in the WSSA/WSWS oral and poster presentation titles."}
title_dt_04 %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,150) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words04 <- title_dt_04  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2004")
```


```{r warning = FALSE} 
# need to stop footnotes' word

pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt_04$word, freq = title_dt_04$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```




# 2005




```{r}
co2005 <- read_html("http://ncwss.org/proceed/2005/proc05/abstracts/cereals.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
cs2005 <- read_html("http://ncwss.org/proceed/2005/proc05/abstracts/corn.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
met2005 <- read_html("http://ncwss.org/proceed/2005/proc05/abstracts/equipment.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
ext2005 <- read_html("http://ncwss.org/proceed/2005/proc05/abstracts/extension.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
for2005 <- read_html("http://ncwss.org/proceed/2005/proc05/abstracts/forage.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
phy2005 <- read_html("http://ncwss.org/proceed/2005/proc05/abstracts/physiology.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
tur2005 <- read_html("http://ncwss.org/proceed/2005/proc05/abstracts/industrial.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
inv2005 <- read_html("http://ncwss.org/proceed/2005/proc05/abstracts/invasive.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
soil2005 <- read_html("http://ncwss.org/proceed/2005/proc05/abstracts/soil.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
soy2005 <- read_html("http://ncwss.org/proceed/2005/proc05/abstracts/soybean.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
hort2005 <- read_html("http://ncwss.org/proceed/2005/proc05/abstracts/sugarbeets.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
eco2005 <- read_html("http://ncwss.org/proceed/2005/proc05/abstracts/ecolbiol.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 
man2005 <- read_html("http://ncwss.org/proceed/2005/proc05/abstracts/ecolmanage.htm") %>% 
  html_nodes(xpath = "//p[.]") %>%
  html_text() 



nc_2005 <- rbind(co2005, cs2005, met2005, ext2005, for2005, phy2005, tur2005, inv2005, soil2005,
                 soy2005, hort2005, eco2005, man2005)
```

```{r warning=FALSE, include=FALSE}
titledm_05 <- data.frame() # as data frame

for (i in 1:length(nc_2005)) {
  print(i)
  titlelines <- data.frame(names = nc_2005[[i]])
  titledm_05 <- bind_rows(titledm_05, titlelines)
} 
```

```{r}
titledm_05$names <- gsub("2,4-D" , "twofourd" , titledm_05$names)
```

```{r}
title_tokens_05 <- titledm_05 %>%
  unnest_tokens(words, names)
```


```{r eval=FALSE, include=FALSE}
authors_05 <- read_html("http://ncwss.org/proceed/2005/proc05/abstracts/author.htm") %>% 
  html_nodes(xpath = "//table[2]") %>%
  html_text() 
authors_05 <- c(authors_05)
authors_05 <- data_frame(authors_05)
#tokerization
authors_tokens_05 <- authors_05 %>%
  unnest_tokens(words, authors_05)
```


```{r }
title_tokens_05 <- anti_join(title_tokens_05, stop_wssaprogram_words_tokens, by = "words") 
title_tokens_05 <- anti_join(title_tokens_05, stopwords_tokens, by = "words") 
title_tokens_05 <- anti_join(title_tokens_05, authors_tokens, by = "words") 
```


```{r}
title_source_05 <- VectorSource(title_tokens_05$words)
title_corpus_05 <- VCorpus(title_source_05)
```



```{r}
title_corpus_05 <- clean_corpus(title_corpus_05)
```



```{r}
title_dtm_05 <- TermDocumentMatrix(title_corpus_05)
title_matrix_05 <- as.matrix(title_dtm_05)
title_v_05 <- sort(rowSums(title_matrix_05), decreasing=TRUE)
title_dt_05 <- data.frame(word = names(title_v_05),freq=title_v_05)
```


```{r}
title_dt_05$word <- gsub("twofourd" , "2,4-D" , title_dt_05$word)
```


```{r fig.cap= "Most frequent words (n=30+) that appeared in the WSSA/WSWS oral and poster presentation titles."}
title_dt_05 %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,150) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words05 <- title_dt_05  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2005")
```


```{r} 
# need to stop footnotes' word

pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt_05$word, freq = title_dt_05$freq, min.freq=1, scale=c(5,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```






# 2006

```{r}
pdf_06 <- pdf_text("docs/nc2006.pdf") %>% 
  strsplit(split = "\n")
```

```{r}
title <- pdf_06[1:20] 
```


```{r warning=FALSE, include=FALSE}
titledm_06 <- data.frame() # as data frame

for (i in 1:length(title)) {
  print(i)
  titlelines_06 <- data.frame(names = title[[i]])
  titledm_06 <- bind_rows(titledm_06, titlelines_06)
} 
```

```{r}
titledm_06$names <- gsub("2,4-D" , "twofourd" , titledm_06$names)
```


```{r}
title_tokens_06 <- titledm_06 %>%
  unnest_tokens(words, names)
```


```{r warning=FALSE, include=FALSE}
authors_06 <- pdf_06[21:28]

authorsdm_06 <- data.frame()

for (i in 1:length(authors)) {
  print(i)
  authorslines_06 <- data.frame(names = authors_06[[i]])
  authorsdm_06 <- bind_rows(authorsdm_06, authorslines_06)
} 

#tokerization
authors_tokens_06 <- authorsdm_06 %>%
  unnest_tokens(words, names)
```



```{r warning=FALSE}
title_tokens_06 <- anti_join(title_tokens_06, authors_tokens_06, by = "words")
```



```{r include=FALSE}
rm_author_06 <- c(1:12) 
rm_authors_number_06 <-c()
for (i in 1:length(rm_author)) {
  print(i)
  rm_authors_numbers_06 <- c(paste0(authors_tokens_06$words, i))
  rm_authors_number_06 <- c(rm_authors_number_06, rm_authors_numbers_06)
}
```


```{r}
rm_authors_06 <- data.frame(rm_authors_number_06) 
rm_authors_06 <- rename(rm_authors_06, words = rm_authors_number_06) 
rm_authors_06$words <- as.character(rm_authors_06$words)
```


```{r }
title_tokens_06 <- anti_join(title_tokens_06, rm_authors_06, by = "words") 
```


```{r }
title_tokens_06 <- anti_join(title_tokens_06, stop_wssaprogram_words_tokens, by = "words") 
title_tokens_06 <- anti_join(title_tokens_06, stopwords_tokens, by = "words") 
title_tokens_06 <- anti_join(title_tokens_06, authors_tokens_06, by = "words") 
```


```{r}
title_source_06 <- VectorSource(title_tokens_06$words)
title_corpus_06 <- VCorpus(title_source_06)
```



```{r}
title_corpus_06 <- clean_corpus(title_corpus_06)
```



```{r}
title_dtm_06 <- TermDocumentMatrix(title_corpus_06)
title_matrix_06 <- as.matrix(title_dtm_06)
title_v_06 <- sort(rowSums(title_matrix_06), decreasing=TRUE)
title_dt_06 <- data.frame(word = names(title_v_06),freq=title_v_06)
```


```{r}
title_dt_06$word <- gsub("twofourd" , "2,4-D" , title_dt_06$word)
```


```{r fig.cap= "Most frequent words (n=30+) that appeared in the WSSA/WSWS oral and poster presentation titles."}
title_dt_06 %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,150) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words06 <- title_dt_06  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2006")
```


```{r} 
# need to stop footnotes' word

pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt_06$word, freq = title_dt_06$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```




# 2007





```{r}
ag2007 <- read_html("http://ncwss.org/proceed/2007/agronomic.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
ex2007 <- read_html("http://ncwss.org/proceed/2007/extension.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
phy2007 <- read_html("http://ncwss.org/proceed/2007/physiology.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
hort2007 <- read_html("http://ncwss.org/proceed/2007/horticulture.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
inv2007 <- read_html("http://ncwss.org/proceed/2007/invasiveweeds.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
bem2007 <- read_html("http://ncwss.org/proceed/2007/biology.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
cm2007 <- read_html("http://ncwss.org/proceed/2007/communication.htm") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
gf2007 <- read_html("http://ncwss.org/proceed/2007/geneflow.htm") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 

nc_2007 <- rbind(ag2007, ex2007, phy2007, hort2007, inv2007, bem2007,  cm2007, gf2007)
```

```{r warning=FALSE, include=FALSE}
titledm_07 <- data.frame() # as data frame

for (i in 1:length(nc_2007)) {
  print(i)
  titlelines_07 <- data.frame(names = nc_2007[[i]])
  titledm_07 <- bind_rows(titledm_07, titlelines_07)
} 
```

```{r}
titledm_07$names <- gsub("2,4-D" , "twofourd" , titledm_07$names)
```


```{r}
title_tokens_07 <- titledm_07 %>%
  unnest_tokens(words, names)
```


```{r}
authors_07 <- read_html("http://ncwss.org/proceed/2007/authorindex.html") %>% 
  html_nodes(xpath = "//table[.]") %>%
  html_text() 
authors_07 <- c(authors_07)
authors_07 <- data_frame(authors_07)
#tokerization
authors_tokens_07 <- authors_07 %>%
  unnest_tokens(words, authors_07)
```



```{r }
title_tokens_07 <- anti_join(title_tokens_07, stop_wssaprogram_words_tokens, by = "words") 
title_tokens_07 <- anti_join(title_tokens_07, stopwords_tokens, by = "words") 
title_tokens_07 <- anti_join(title_tokens_07, authors_tokens_07, by = "words") 
```


```{r}
title_source_07 <- VectorSource(title_tokens_07$words)
title_corpus_07 <- VCorpus(title_source_07)
```



```{r}
title_corpus_07 <- clean_corpus(title_corpus_07)
```



```{r}
title_dtm_07 <- TermDocumentMatrix(title_corpus_07)
title_matrix_07 <- as.matrix(title_dtm_07)
title_v_07 <- sort(rowSums(title_matrix_07), decreasing=TRUE)
title_dt_07 <- data.frame(word = names(title_v_07),freq=title_v_07)
```


```{r}
title_dt_07$word <- gsub("twofourd" , "2,4-D" , title_dt_07$word)
```


```{r fig.cap= "Most frequent words (n=30+) that appeared in the WSSA/WSWS oral and poster presentation titles."}
title_dt_07 %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,150) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words07 <- title_dt_07  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2007")
```


```{r} 
# need to stop footnotes' word

pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt_07$word, freq = title_dt_07$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```









# 2008


```{r}
ag2008 <- read_html("http://ncwss.org/proceed/2008/agronomic.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
ex2008 <- read_html("http://ncwss.org/proceed/2008/extension.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
phy2008 <- read_html("http://ncwss.org/proceed/2008/physiology.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
hort2008 <- read_html("http://ncwss.org/proceed/2008/horticulture.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
inv2008 <- read_html("http://ncwss.org/proceed/2008/invasiveweeds.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
bem2008 <- read_html("http://ncwss.org/proceed/2008/biology.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
swr2008 <- read_html("http://ncwss.org/proceed/2008/HRC%20Symposium.htm") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
siw2008 <- read_html("http://ncwss.org/proceed/2008/IWM%20symposium.htm") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
siv2008 <- read_html("http://ncwss.org/proceed/2008/MIPN%20Symposium.htm") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 

nc_2008 <- rbind(ag2008, ex2008, phy2008, hort2008, inv2008, bem2008, swr2008, siw2008, siv2008)
```


```{r warning=FALSE, include=FALSE}
titledm_08 <- data.frame() # as data frame

for (i in 1:length(nc_2008)) {
  print(i)
  titlelines_08 <- data.frame(names = nc_2008[[i]])
  titledm_08 <- bind_rows(titledm_08, titlelines_08)
} 
```

```{r}
titledm_08$names <- gsub("2,4-D" , "twofourd" , titledm_08$names)
```

```{r}
title_tokens_08 <- titledm_08 %>%
  unnest_tokens(words, names)
```


```{r}
# Authors 2008
authors_08 <- read_html("http://ncwss.org/proceed/2008/authorindex.html") %>% 
  html_nodes(xpath = "//table[.]") %>%
  html_text() 
authors_08 <- c(authors_08)
authors_08 <- data_frame(authors_08)
#tokerization
authors_tokens_08 <- authors_08 %>%
  unnest_tokens(words, authors_08)
```



```{r }
title_tokens_08 <- anti_join(title_tokens_08, stop_wssaprogram_words_tokens, by = "words") 
title_tokens_08 <- anti_join(title_tokens_08, stopwords_tokens, by = "words") 
title_tokens_08 <- anti_join(title_tokens_08, authors_tokens_08, by = "words") 
```




```{r}
title_source_08 <- VectorSource(title_tokens_08$words)
title_corpus_08 <- VCorpus(title_source_08)
```




```{r}
title_corpus_08 <- clean_corpus(title_corpus_08)
```



```{r}
title_dtm_08 <- TermDocumentMatrix(title_corpus_08)
title_matrix_08 <- as.matrix(title_dtm_08)
title_v_08 <- sort(rowSums(title_matrix_08), decreasing=TRUE)
title_dt_08 <- data.frame(word = names(title_v_08),freq=title_v_08)
```


```{r}
title_dt_08$word <- gsub("twofourd" , "2,4-D" , title_dt_08$word)
```


```{r fig.cap= "Most frequent words (n=30+) that appeared in the WSSA/WSWS oral and poster presentation titles."}
title_dt_08 %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,150) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words08 <- title_dt_08  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2008")
```


```{r} 
# need to stop footnotes' word

pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt_08$word, freq = title_dt_08$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```





# 2009

```{r}
ag2009 <- read_html("http://ncwss.org/proceed/2009/agronomic.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
ex2009 <- read_html("http://ncwss.org/proceed/2009/extension.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
phy2009 <- read_html("http://ncwss.org/proceed/2009/physiology.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
hort2009 <- read_html("http://ncwss.org/proceed/2009/horticulture.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
inv2009 <- read_html("http://ncwss.org/proceed/2009/invasiveweeds.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
bem2009 <- read_html("http://ncwss.org/proceed/2009/biology.html") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
lea2009 <- read_html("http://ncwss.org/proceed/2009/Learning%20store%20symposium.htm") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 
st2009 <- read_html("http://ncwss.org/proceed/2009/statistics%20symposium.htm") %>% 
  html_nodes(xpath = "//strong") %>%
  html_text() 


nc_2009 <- rbind(ag2009, ex2009, phy2009, hort2009, inv2009, bem2009, lea2009, st2009)
```

```{r warning=FALSE, include=FALSE}
titledm_09 <- data.frame() # as data frame

for (i in 1:length(nc_2009)) {
  print(i)
  titlelines_09 <- data.frame(names = nc_2009[[i]])
  titledm_09 <- bind_rows(titledm_09, titlelines_09)
} 
```

```{r}
titledm_09$names <- gsub("2,4-D" , "twofourd" , titledm_09$names)
```

```{r}
title_tokens_09 <- titledm_09 %>%
  unnest_tokens(words, names)
```



```{r}
# Authors 2009
authors_09 <- read_html("http://ncwss.org/proceed/2009/authorindex.html") %>% 
  html_nodes(xpath = "//table[.]") %>%
  html_text() 
authors_09 <- c(authors_09)
authors_09 <- data_frame(authors_09)
#tokerization
authors_tokens_09 <- authors_09 %>%
  unnest_tokens(words, authors_09)
```



```{r }
title_tokens_09 <- anti_join(title_tokens_09, stop_wssaprogram_words_tokens, by = "words") 
title_tokens_09 <- anti_join(title_tokens_09, stopwords_tokens, by = "words") 
title_tokens_09 <- anti_join(title_tokens_09, authors_tokens_09, by = "words") 
```





```{r}
title_source_09 <- VectorSource(title_tokens_09$words)
title_corpus_09 <- VCorpus(title_source_09)
```



```{r}
title_corpus_09 <- clean_corpus(title_corpus_09)
```



```{r}
title_dtm_09 <- TermDocumentMatrix(title_corpus_09)
title_matrix_09 <- as.matrix(title_dtm_09)
title_v_09 <- sort(rowSums(title_matrix_09), decreasing=TRUE)
title_dt_09 <- data.frame(word = names(title_v_09),freq=title_v_09)
```


```{r}
title_dt_09$word <- gsub("twofourd" , "2,4-D" , title_dt_09$word)
```


```{r fig.cap= "Most frequent words (n=30+) that appeared in the WSSA/WSWS oral and poster presentation titles."}
title_dt_09 %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,150) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words09 <- title_dt_09  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2009")
```


```{r} 
# need to stop footnotes' word

pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt_09$word, freq = title_dt_09$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```









# 2010 - 2019





```{r}
nc2010 <- download("http://ncwss.org/wp-content/uploads/2015/03/NCWSS-2010-Proceedings.pdf", "nc2010.pdf", mode = "wb")
nc2011 <- download("http://ncwss.org/wp-content/uploads/2015/03/NCWSS-2011-Proceedings.pdf", "nc2011.pdf", mode = "wb")
nc2012 <- download("http://ncwss.org/wp-content/uploads/2015/03/NCWSS-2012-Proceedings.pdf", "nc2012.pdf", mode = "wb")
nc2013 <- download("http://ncwss.org/wp-content/uploads/2015/03/NCWSS-2013-Proceedings.pdf", "nc2013.pdf", mode = "wb")
nc2014 <- download("http://ncwss.org/wp-content/uploads/2015/03/NCWSS-2014-Proceedings.pdf", "nc2014.pdf", mode = "wb")
nc2015 <- download("http://ncwss.org/wp-content/uploads/2015/03/2015-North-Central-Weed-Science-Society-Proceedings-Final.pdf", "nc2015.pdf", mode = "wb")
nc2016 <- download("http://ncwss.org/wp-content/uploads/2016-North-Central-Weed-Science-Society-Proceedings.pdf", "nc2016.pdf", mode = "wb")
nc2017 <- download("https://ncwss.org/wp-content/uploads/2017-North-Central-Weed-Science-Society-Proceedings-w_attendees.pdf", "nc2017.pdf", mode = "wb")
nc2018 <- download("https://ncwss.org/wp-content/uploads/NCWSS-Annual-Meeting-Proceedings-2018.pdf", "nc2018.pdf", mode = "wb")
nc2019 <- download("https://ncwss.org/wp-content/uploads/NCWSS-2019-Proceedings-FINAL.pdf", "nc2019.pdf", mode = "wb")
```

# 2010

```{r}
pdf_10 <- pdf_text("nc2010.pdf") %>% 
  strsplit(split = "\n")
```

```{r}
#title <- pdf_10[1:13] 
```


```{r warning=FALSE, include=FALSE}
titledm_10 <- data.frame() # as data frame

for (i in 1:length(pdf_10)) {
  print(i)
  titlelines_10 <- data.frame(names = pdf_10[[i]])
  titledm_10 <- bind_rows(titledm_10, titlelines_10)
} 
```

```{r}
titledm_10$names <- gsub("2,4-D" , "twofourd" , titledm_10$names)
```


```{r}
title_tokens_10 <- titledm_10 %>%
  unnest_tokens(words, names)
```


```{r warning=FALSE, include=FALSE}
authors_10 <- pdf_10[85:91]

authorsdm_10 <- data.frame()

for (i in 1:length(authors_10)) {
  print(i)
  authorslines_10 <- data.frame(names = authors_10[[i]])
  authorsdm_10 <- bind_rows(authorsdm_10, authorslines_10)
} 

#tokerization
authors_tokens_10 <- authorsdm_10 %>%
  unnest_tokens(words, names)
```

```{r warning=FALSE}
titles_tokens_10 <- anti_join(title_tokens_10, authors_tokens_10, by = "words")
```


```{r include=FALSE}
rm_author_10 <- c(1:12) 
rm_authors_number_10 <-c()
for (i in 1:length(rm_author_10)) {
  print(i)
  rm_authors_numbers_10 <- c(paste0(authors_tokens_10$words, i))
  rm_authors_number_10 <- c(rm_authors_number_10, rm_authors_numbers_10)
}
```

```{r}
rm_authors_10 <- data.frame(rm_authors_number_10) 
rm_authors_10 <- rename(rm_authors_10, words = rm_authors_number_10) 
rm_authors_10$words <- as.character(rm_authors_10$words)
```


```{r }
title_tokens_10 <- anti_join(title_tokens_10, rm_authors_10, by = "words") 
title_tokens_10 <- anti_join(title_tokens_10, stop_wssaprogram_words_tokens, by = "words") 
title_tokens_10 <- anti_join(title_tokens_10, stopwords_tokens, by = "words") 
title_tokens_10 <- anti_join(title_tokens_10, authors_tokens_10, by = "words") 
```


```{r}
title_source_10 <- VectorSource(title_tokens_10$words)
title_corpus_10 <- VCorpus(title_source_10)
```



```{r}
title_corpus_10 <- clean_corpus(title_corpus_10)
```



```{r}
title_dtm_10 <- TermDocumentMatrix(title_corpus_10)
title_matrix_10 <- as.matrix(title_dtm_10)
title_v_10 <- sort(rowSums(title_matrix_10), decreasing=TRUE)
title_dt_10 <- data.frame(word = names(title_v_10),freq=title_v_10)
```


```{r}
title_dt_10$word <- gsub("twofourd" , "2,4-D" , title_dt_10$word)
```


```{r fig.cap= "Most frequent words (n=30+) that appeared in the WSSA/WSWS oral and poster presentation titles."}
title_dt_10 %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,150) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words10 <- title_dt_10  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2010")
```


```{r warning=FALSE} 
# need to stop footnotes' word

pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt_10$word, freq = title_dt_10$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```






# 2011

```{r}
pdf_11 <- pdf_text("nc2011.pdf") %>% 
  strsplit(split = "\n")
```


```{r warning=FALSE, include=FALSE}
titledm_11 <- data.frame() # as data frame

for (i in 1:length(pdf_11)) {
  print(i)
  titlelines_11 <- data.frame(names = pdf_11[[i]])
  titledm_11 <- bind_rows(titledm_11, titlelines_11)
} 
```

```{r}
titledm_11$names <- gsub("2,4-D" , "twofourd" , titledm_11$names)
```


```{r}
title_tokens_11 <- titledm_11 %>%
  unnest_tokens(words, names)
```



```{r warning=FALSE, include=FALSE}
authors_11 <- pdf_11[152:157]

authorsdm_11 <- data.frame()

for (i in 1:length(authors_11)) {
  print(i)
  authorslines_11 <- data.frame(names = authors_11[[i]])
  authorsdm_11 <- bind_rows(authorsdm_11, authorslines_11)
} 

#tokerization
authors_tokens_11 <- authorsdm_11 %>%
  unnest_tokens(words, names)
```

```{r warning=FALSE}
titles_tokens_11 <- anti_join(title_tokens_11, authors_tokens_11, by = "words")
```


```{r include=FALSE}
rm_author_11 <- c(1:12) 
rm_authors_number_11 <-c()
for (i in 1:length(rm_author_11)) {
  print(i)
  rm_authors_numbers_11 <- c(paste0(authors_tokens_11$words, i))
  rm_authors_number_11 <- c(rm_authors_number_11, rm_authors_numbers_11)
}

rm_authors_11 <- data.frame(rm_authors_number_11) 
rm_authors_11 <- rename(rm_authors_11, words = rm_authors_number_11) 
rm_authors_11$words <- as.character(rm_authors_11$words)
```


```{r }
title_tokens_11 <- anti_join(title_tokens_11, rm_authors_11, by = "words") 
title_tokens_11 <- anti_join(title_tokens_11, stop_wssaprogram_words_tokens, by = "words") 
title_tokens_11 <- anti_join(title_tokens_11, stopwords_tokens, by = "words") 
title_tokens_11 <- anti_join(title_tokens_11, authors_tokens_11, by = "words") 
```


```{r}
title_source_11 <- VectorSource(title_tokens_11$words)
title_corpus_11 <- VCorpus(title_source_11)
```



```{r}
title_corpus_11 <- clean_corpus(title_corpus_11)
```



```{r}
title_dtm_11 <- TermDocumentMatrix(title_corpus_11)
title_matrix_11 <- as.matrix(title_dtm_11)
title_v_11 <- sort(rowSums(title_matrix_11), decreasing=TRUE)
title_dt_11 <- data.frame(word = names(title_v_11),freq=title_v_11)
```


```{r}
title_dt_11$word <- gsub("twofourd" , "2,4-D" , title_dt_11$word)
```


```{r fig.cap= "Most frequent words (n=10+) that appeared in the WSSA/WSWS oral and poster presentation titles."}
title_dt_11 %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,150) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words11 <- title_dt_11  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2011")
```



```{r warning=FALSE} 
pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt_11$word, freq = title_dt_11$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```



# 2012

```{r}
pdf_12 <- pdf_text("nc2012.pdf") %>% 
  strsplit(split = "\n")
```

```{r}
#title <- pdf_12[2:15] 
```


```{r warning=FALSE, include=FALSE}
titledm_12 <- data.frame() # as data frame

for (i in 1:length(title)) {
  print(i)
  titlelines_12 <- data.frame(names = pdf_12[[i]])
  titledm_12 <- bind_rows(titledm_12, titlelines_12)
} 
```

```{r}
titledm$names <- gsub("2,4-D" , "twofourd" , titledm$names)
```


```{r}
title_tokens <- titledm %>%
  unnest_tokens(words, names)
```


```{r warning=FALSE, include=FALSE}
authors <- pdf_12[101:104]

authorsdm <- data.frame()

for (i in 1:length(authors)) {
  print(i)
  authorslines <- data.frame(names = authors[[i]])
  authorsdm <- bind_rows(authorsdm, authorslines)
} 

#tokerization
authors_tokens <- authorsdm %>%
  unnest_tokens(words, names)
```

```{r warning=FALSE}
titles_tokens_clean <- anti_join(title_tokens, authors_tokens, by = "words")
```


```{r include=FALSE}
rm_author <- c(1:12) 
rm_authors_number <-c()
for (i in 1:length(rm_author)) {
  print(i)
  rm_authors_numbers <- c(paste0(authors_tokens$words, i))
  rm_authors_number <- c(rm_authors_number, rm_authors_numbers)
}
```


```{r}
rm_authors <- data.frame(rm_authors_number) 
rm_authors <- rename(rm_authors, words = rm_authors_number) 
rm_authors$words <- as.character(rm_authors$words)
```


```{r }
text_tokens <- anti_join(title_tokens, authors_tokens, by = "words") 
text_tokens <- anti_join(text_tokens, names_tokens, by = "words") 
```


```{r}
title_source <- VectorSource(text_tokens$words)
title_corpus <- VCorpus(title_source)
```



```{r}
# this code section will take long (~3 min) to run. 
clean_corpus <- function(corpus){
  corpus <- tm_map(corpus, removePunctuation) # remove punctuation
  corpus <- tm_map(corpus, content_transformer(tolower)) # remove punctuation
  corpus <- tm_map(corpus, removeNumbers) # remove numbers
  corpus <- tm_map(corpus, removeWords, stopwords) # remove stop words
  corpus
}

title_corpus <- clean_corpus(title_corpus)
```



```{r}
title_dtm <- TermDocumentMatrix(title_corpus)
title_matrix <- as.matrix(title_dtm)
title_v <- sort(rowSums(title_matrix), decreasing=TRUE)
title_dt <- data.frame(word = names(title_v),freq=title_v)
```


```{r}
title_dt$word <- gsub("twofourd" , "2,4-D" , title_dt$word)
```


```{r}
title_dt %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,50) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words12 <- title_dt  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2012")
```

```{r warning=FALSE} 
pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt$word, freq = title_dt$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```

# 2013

```{r}
pdf_13 <- pdf_text("nc2013.pdf") %>% 
  strsplit(split = "\n")
```

```{r}
title <- pdf_13[2:18] 
```


```{r warning=FALSE, include=FALSE}
titledm <- data.frame() # as data frame

for (i in 1:length(title)) {
  print(i)
  titlelines <- data.frame(names = title[[i]])
  titledm <- bind_rows(titledm, titlelines)
} 
```

```{r}
titledm$names <- gsub("2,4-D" , "twofourd" , titledm$names)
```


```{r}
title_tokens <- titledm %>%
  unnest_tokens(words, names)
```



```{r warning=FALSE, include=FALSE}
authors <- pdf_13[122:125]

authorsdm <- data.frame()

for (i in 1:length(authors)) {
  print(i)
  authorslines <- data.frame(names = authors[[i]])
  authorsdm <- bind_rows(authorsdm, authorslines)
} 

#tokerization
authors_tokens <- authorsdm %>%
  unnest_tokens(words, names)
```

```{r warning=FALSE}
titles_tokens_clean <- anti_join(title_tokens, authors_tokens, by = "words")
```


```{r include=FALSE}
rm_author <- c(1:12) 
rm_authors_number <-c()
for (i in 1:length(rm_author)) {
  print(i)
  rm_authors_numbers <- c(paste0(authors_tokens$words, i))
  rm_authors_number <- c(rm_authors_number, rm_authors_numbers)
}
```


```{r}
rm_authors <- data.frame(rm_authors_number) 
rm_authors <- rename(rm_authors, words = rm_authors_number) 
rm_authors$words <- as.character(rm_authors$words)
```


```{r }
text_tokens <- anti_join(title_tokens, authors_tokens, by = "words") 
text_tokens <- anti_join(text_tokens, stopwords_tokens, by = "words") 
```


```{r}
title_source <- VectorSource(text_tokens$words)
title_corpus <- VCorpus(title_source)
```



```{r}
# this code section will take long (~3 min) to run. 
clean_corpus <- function(corpus){
  corpus <- tm_map(corpus, removePunctuation) # remove punctuation
  corpus <- tm_map(corpus, content_transformer(tolower)) # remove punctuation
  corpus <- tm_map(corpus, removeNumbers) # remove numbers
  corpus <- tm_map(corpus, removeWords, stopwords_en) # remove stop words
  corpus
}

title_corpus <- clean_corpus(title_corpus)
```



```{r}
title_dtm <- TermDocumentMatrix(title_corpus)
title_matrix <- as.matrix(title_dtm)
title_v <- sort(rowSums(title_matrix), decreasing=TRUE)
title_dt <- data.frame(word = names(title_v),freq=title_v)
```


```{r}
title_dt$word <- gsub("twofourd" , "2,4-D" , title_dt$word)
```


```{r}
title_dt %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + ylim(0,50) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words13 <- title_dt  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2013")
```

```{r} 
pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt$word, freq = title_dt$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```



# 2014

```{r}
pdf_14 <- pdf_text("nc2014.pdf") %>% 
  strsplit(split = "\n")
```

```{r}
title <- pdf_14[2:14] 
```


```{r warning=FALSE, include=FALSE}
titledm <- data.frame() # as data frame

for (i in 1:length(title)) {
  print(i)
  titlelines <- data.frame(names = title[[i]])
  titledm <- bind_rows(titledm, titlelines)
} 
```

```{r}
titledm$names <- gsub("2,4-D" , "twofourd" , titledm$names)
```


```{r}
title_tokens <- titledm %>%
  unnest_tokens(words, names)
```



```{r warning=FALSE, include=FALSE}
authors <- pdf_14[87:90]

authorsdm <- data.frame()

for (i in 1:length(authors)) {
  print(i)
  authorslines <- data.frame(names = authors[[i]])
  authorsdm <- bind_rows(authorsdm, authorslines)
} 

#tokerization
authors_tokens <- authorsdm %>%
  unnest_tokens(words, names)
```

```{r warning=FALSE}
titles_tokens_clean <- anti_join(title_tokens, authors_tokens, by = "words")
```


```{r include=FALSE}
rm_author <- c(1:12) 
rm_authors_number <-c()
for (i in 1:length(rm_author)) {
  print(i)
  rm_authors_numbers <- c(paste0(authors_tokens$words, i))
  rm_authors_number <- c(rm_authors_number, rm_authors_numbers)
}
```


```{r}
rm_authors <- data.frame(rm_authors_number) 
rm_authors <- rename(rm_authors, words = rm_authors_number) 
rm_authors$words <- as.character(rm_authors$words)
```


```{r }
text_tokens <- anti_join(title_tokens, authors_tokens, by = "words") 
text_tokens <- anti_join(text_tokens, stopwords_tokens, by = "words") 
```


```{r}
title_source <- VectorSource(text_tokens$words)
title_corpus <- VCorpus(title_source)
```



```{r}
# this code section will take long (~3 min) to run. 
clean_corpus <- function(corpus){
  corpus <- tm_map(corpus, removePunctuation) # remove punctuation
  corpus <- tm_map(corpus, content_transformer(tolower)) # remove punctuation
  corpus <- tm_map(corpus, removeNumbers) # remove numbers
  corpus <- tm_map(corpus, removeWords, stopwords_en) # remove stop words
  corpus
}

title_corpus <- clean_corpus(title_corpus)
```



```{r}
title_dtm <- TermDocumentMatrix(title_corpus)
title_matrix <- as.matrix(title_dtm)
title_v <- sort(rowSums(title_matrix), decreasing=TRUE)
title_dt <- data.frame(word = names(title_v),freq=title_v)
```


```{r}
title_dt$word <- gsub("twofourd" , "2,4-D" , title_dt$word)
```


```{r}
title_dt %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,50) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words14 <- title_dt  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2014")
```


```{r} 
pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt$word, freq = title_dt$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```



# 2015

```{r}
pdf_15 <- pdf_text("nc2015.pdf") %>% 
  strsplit(split = "\n")
```

```{r}
title <- pdf_15[3:17] # need to check pdf (overlap)
```


```{r warning=FALSE, include=FALSE}
titledm <- data.frame() # as data frame

for (i in 1:length(title)) {
  print(i)
  titlelines <- data.frame(names = title[[i]])
  titledm <- bind_rows(titledm, titlelines)
} 
```

```{r}
titledm$names <- gsub("2,4-D" , "twofourd" , titledm$names)
```


```{r}
title_tokens <- titledm %>%
  unnest_tokens(words, names)
```



```{r warning=FALSE, include=FALSE}
authors <- pdf_15[93:98]

authorsdm <- data.frame()

for (i in 1:length(authors)) {
  print(i)
  authorslines <- data.frame(names = authors[[i]])
  authorsdm <- bind_rows(authorsdm, authorslines)
} 

#tokerization
authors_tokens <- authorsdm %>%
  unnest_tokens(words, names)
```

```{r warning=FALSE}
titles_tokens_clean <- anti_join(title_tokens, authors_tokens, by = "words")
```


```{r include=FALSE}
rm_author <- c(1:12) 
rm_authors_number <-c()
for (i in 1:length(rm_author)) {
  print(i)
  rm_authors_numbers <- c(paste0(authors_tokens$words, i))
  rm_authors_number <- c(rm_authors_number, rm_authors_numbers)
}
```


```{r}
rm_authors <- data.frame(rm_authors_number) 
rm_authors <- rename(rm_authors, words = rm_authors_number) 
rm_authors$words <- as.character(rm_authors$words)
```


```{r }
text_tokens <- anti_join(title_tokens, authors_tokens, by = "words") 
text_tokens <- anti_join(text_tokens, stopwords_tokens, by = "words") 
```


```{r}
title_source <- VectorSource(text_tokens$words)
title_corpus <- VCorpus(title_source)
```



```{r}
# this code section will take long (~3 min) to run. 
clean_corpus <- function(corpus){
  corpus <- tm_map(corpus, removePunctuation) # remove punctuation
  corpus <- tm_map(corpus, content_transformer(tolower)) # remove punctuation
  corpus <- tm_map(corpus, removeNumbers) # remove numbers
  corpus <- tm_map(corpus, removeWords, stopwords_en) # remove stop words
  corpus
}

title_corpus <- clean_corpus(title_corpus)
```



```{r}
title_dtm <- TermDocumentMatrix(title_corpus)
title_matrix <- as.matrix(title_dtm)
title_v <- sort(rowSums(title_matrix), decreasing=TRUE)
title_dt <- data.frame(word = names(title_v),freq=title_v)
```


```{r}
title_dt$word <- gsub("twofourd" , "2,4-D" , title_dt$word)
```


```{r}
title_dt %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,50) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words15 <- title_dt  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2015")
```

```{r} 
pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt$word, freq = title_dt$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```






# 2016

```{r}
pdf_16 <- pdf_text("nc2016.pdf") %>% 
  strsplit(split = "\n")
```

```{r}
title <- pdf_16[2:15] # need to check pdf (overlap)
```


```{r warning=FALSE, include=FALSE}
titledm <- data.frame() # as data frame

for (i in 1:length(title)) {
  print(i)
  titlelines <- data.frame(names = title[[i]])
  titledm <- bind_rows(titledm, titlelines)
} 
```

```{r}
titledm$names <- gsub("2,4-D" , "twofourd" , titledm$names)
```


```{r}
title_tokens <- titledm %>%
  unnest_tokens(words, names)
```



```{r warning=FALSE, include=FALSE}
authors <- pdf_16[90:93]

authorsdm <- data.frame()

for (i in 1:length(authors)) {
  print(i)
  authorslines <- data.frame(names = authors[[i]])
  authorsdm <- bind_rows(authorsdm, authorslines)
} 

#tokerization
authors_tokens <- authorsdm %>%
  unnest_tokens(words, names)
```

```{r warning=FALSE}
titles_tokens_clean <- anti_join(title_tokens, authors_tokens, by = "words")
```


```{r include=FALSE}
rm_author <- c(1:12) 
rm_authors_number <-c()
for (i in 1:length(rm_author)) {
  print(i)
  rm_authors_numbers <- c(paste0(authors_tokens$words, i))
  rm_authors_number <- c(rm_authors_number, rm_authors_numbers)
}
```


```{r}
rm_authors <- data.frame(rm_authors_number) 
rm_authors <- rename(rm_authors, words = rm_authors_number) 
rm_authors$words <- as.character(rm_authors$words)
```


```{r}
titles_clean_clean <- anti_join(titles_tokens_clean, rm_authors, by = "words")
```







```{r}
title_source <- VectorSource(titles_clean_clean$words)
title_corpus <- VCorpus(title_source)
```



```{r}
# this code section will take long (~3 min) to run. 
clean_corpus <- function(corpus){
  corpus <- tm_map(corpus, removePunctuation) # remove punctuation
  corpus <- tm_map(corpus, content_transformer(tolower)) # remove punctuation
  corpus <- tm_map(corpus, removeNumbers) # remove numbers
  corpus <- tm_map(corpus, removeWords, stopwords_en) # remove stop words
  corpus
}

title_corpus <- clean_corpus(title_corpus)
```



```{r}
title_dtm <- TermDocumentMatrix(title_corpus)
title_matrix <- as.matrix(title_dtm)
title_v <- sort(rowSums(title_matrix), decreasing=TRUE)
title_dt <- data.frame(word = names(title_v),freq=title_v)
```


```{r}
title_dt$word <- gsub("twofourd" , "2,4-D" , title_dt$word)
```


```{r}
title_dt %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,50) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words16 <- title_dt  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2016")
```

```{r} 
pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt$word, freq = title_dt$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```



# 2017

```{r}
pdf_17 <- pdf_text("nc2017.pdf") %>% 
  strsplit(split = "\n")
```

```{r}
title <- pdf_17[2:17] # need to check pdf (overlap)
```


```{r warning=FALSE, include=FALSE}
titledm <- data.frame() # as data frame

for (i in 1:length(title)) {
  print(i)
  titlelines <- data.frame(names = title[[i]])
  titledm <- bind_rows(titledm, titlelines)
} 
```

```{r}
titledm$names <- gsub("2,4-D" , "twofourd" , titledm$names)
```


```{r}
title_tokens <- titledm %>%
  unnest_tokens(words, names)
```



```{r warning=FALSE, include=FALSE}
authors <- pdf_17[102:107]

authorsdm <- data.frame()

for (i in 1:length(authors)) {
  print(i)
  authorslines <- data.frame(names = authors[[i]])
  authorsdm <- bind_rows(authorsdm, authorslines)
} 

#tokerization
authors_tokens <- authorsdm %>%
  unnest_tokens(words, names)
```

```{r warning=FALSE}
titles_tokens_clean <- anti_join(title_tokens, authors_tokens, by = "words")
```


```{r include=FALSE}
rm_author <- c(1:12) 
rm_authors_number <-c()
for (i in 1:length(rm_author)) {
  print(i)
  rm_authors_numbers <- c(paste0(authors_tokens$words, i))
  rm_authors_number <- c(rm_authors_number, rm_authors_numbers)
}
```


```{r}
rm_authors <- data.frame(rm_authors_number) 
rm_authors <- rename(rm_authors, words = rm_authors_number) 
rm_authors$words <- as.character(rm_authors$words)
```


```{r}
titles_clean_clean <- anti_join(titles_tokens_clean, rm_authors, by = "words")
```





```{r}
# cities and states
geography <- corpora("geography/us_cities") 
cities <- geography$cities
stopwords_cities <- c(cities$city) # stop cities words 
stopwords_cities <- tolower(stopwords_cities)  # making small caps
stopwords_state <- c(cities$state) # stop state words 
stopwords_state <- tolower(stopwords_state) # making lowercase

#country
country <- corpora("geography/countries") # stop country words 
stopwords_countries <- c(country$countries) # stop countries words 
stopwords_countries <- tolower(stopwords_countries) # making lowercase

#capitals
capitals <- corpora("geography/us_state_capitals")
capitals <- c(capitals$capitals)  # stop US capital words 
stopwords_capitals <- c(capitals$capital) # stop us capitals words 
stopwords_capitals <- tolower(stopwords_capitals) # making lowercase

#english
Enlish <-corpora("words/stopwords/en")  
stopwords_en <- c(Enlish$stopWords) # stop english words 
stopwords_en <- tolower(stopwords_en) # making lowercase
```





```{r}
title_source <- VectorSource(titles_clean_clean$words)
title_corpus <- VCorpus(title_source)
```



```{r}
# this code section will take long (~3 min) to run. 
clean_corpus <- function(corpus){
  corpus <- tm_map(corpus, removePunctuation) # remove punctuation
  corpus <- tm_map(corpus, content_transformer(tolower)) # remove punctuation
  corpus <- tm_map(corpus, removeNumbers) # remove numbers
  corpus <- tm_map(corpus, removeWords, stopwords_en) # remove stop words
  corpus
}

title_corpus <- clean_corpus(title_corpus)
```



```{r}
title_dtm <- TermDocumentMatrix(title_corpus)
title_matrix <- as.matrix(title_dtm)
title_v <- sort(rowSums(title_matrix), decreasing=TRUE)
title_dt <- data.frame(word = names(title_v),freq=title_v)
```


```{r}
title_dt$word <- gsub("twofourd" , "2,4-D" , title_dt$word)
```


```{r}
title_dt %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,50) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words17 <- title_dt  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1) %>% 
  mutate(year = "2017")
```

```{r} 
pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt$word, freq = title_dt$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```




# 2018

```{r}
pdf_18 <- pdf_text("nc2018.pdf") %>% 
  strsplit(split = "\n")
```

```{r}
title <- pdf_18[2:15] # need to check pdf (overlap)
```


```{r warning=FALSE, include=FALSE}
titledm <- data.frame() # as data frame

for (i in 1:length(title)) {
  print(i)
  titlelines <- data.frame(names = title[[i]])
  titledm <- bind_rows(titledm, titlelines)
} 
```

```{r}
titledm$names <- gsub("2,4-D" , "twofourd" , titledm$names)
```


```{r}
title_tokens <- titledm %>%
  unnest_tokens(words, names)
```



```{r warning=FALSE, include=FALSE}
authors <- pdf_18[108:112]

authorsdm <- data.frame()

for (i in 1:length(authors)) {
  print(i)
  authorslines <- data.frame(names = authors[[i]])
  authorsdm <- bind_rows(authorsdm, authorslines)
} 

#tokerization
authors_tokens <- authorsdm %>%
  unnest_tokens(words, names)
```

```{r warning=FALSE}
titles_tokens_clean <- anti_join(title_tokens, authors_tokens, by = "words")
```


```{r include=FALSE}
rm_author <- c(1:12) 
rm_authors_number <-c()
for (i in 1:length(rm_author)) {
  print(i)
  rm_authors_numbers <- c(paste0(authors_tokens$words, i))
  rm_authors_number <- c(rm_authors_number, rm_authors_numbers)
}
```


```{r}
rm_authors <- data.frame(rm_authors_number) 
rm_authors <- rename(rm_authors, words = rm_authors_number) 
rm_authors$words <- as.character(rm_authors$words)
```


```{r}
titles_clean_clean <- anti_join(titles_tokens_clean, rm_authors, by = "words")
```








```{r}
title_source <- VectorSource(titles_clean_clean$words)
title_corpus <- VCorpus(title_source)
```



```{r}
# this code section will take long (~3 min) to run. 
clean_corpus <- function(corpus){
  corpus <- tm_map(corpus, removePunctuation) # remove punctuation
  corpus <- tm_map(corpus, content_transformer(tolower)) # remove punctuation
  corpus <- tm_map(corpus, removeNumbers) # remove numbers
  corpus <- tm_map(corpus, removeWords, stopwords_en) # remove stop words
  corpus
}

title_corpus <- clean_corpus(title_corpus)
```



```{r}
title_dtm <- TermDocumentMatrix(title_corpus)
title_matrix <- as.matrix(title_dtm)
title_v <- sort(rowSums(title_matrix), decreasing=TRUE)
title_dt <- data.frame(word = names(title_v),freq=title_v)
```


```{r}
title_dt$word <- gsub("twofourd" , "2,4-D" , title_dt$word)
```


```{r}
title_dt %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,50) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```

```{r}
words18 <- title_dt  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1)  %>% 
  mutate(year = "2018") 
```

```{r} 
pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt$word, freq = title_dt$freq, min.freq=1, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```






# 2019

```{r}
pdf_19 <- pdf_text("nc2019.pdf") %>% 
  strsplit(split = "\n")
```

```{r}
title <- pdf_19[2:15] # need to check pdf (overlap)
```


```{r warning=FALSE, include=FALSE}
titledm <- data.frame() # as data frame

for (i in 1:length(title)) {
  print(i)
  titlelines <- data.frame(names = title[[i]])
  titledm <- bind_rows(titledm, titlelines)
} 
```

```{r}
titledm$names <- gsub("2,4-D" , "twofourd" , titledm$names)
```


```{r}
title_tokens <- titledm %>%
  unnest_tokens(words, names)
```

```{r}
head(title_tokens, n=5)
```

```{r warning=FALSE, include=FALSE}
authors <- pdf_18[108:112]

authorsdm <- data.frame()

for (i in 1:length(authors)) {
  print(i)
  authorslines <- data.frame(names = authors[[i]])
  authorsdm <- bind_rows(authorsdm, authorslines)
} 

#tokerization
authors_tokens <- authorsdm %>%
  unnest_tokens(words, names)
```

```{r warning=FALSE}
titles_tokens_clean <- anti_join(title_tokens, authors_tokens, by = "words")
```


```{r include=FALSE}
rm_author <- c(108:112) 
rm_authors_number <-c()
for (i in 1:length(rm_author)) {
  print(i)
  rm_authors_numbers <- c(paste0(authors_tokens$words, i))
  rm_authors_number <- c(rm_authors_number, rm_authors_numbers)
}
```


```{r}
rm_authors <- data.frame(rm_authors_number) 
rm_authors <- rename(rm_authors, words = rm_authors_number) 
rm_authors$words <- as.character(rm_authors$words)
```


```{r}
titles_clean_clean <- anti_join(titles_tokens_clean, rm_authors, by = "words")
```



```{r}
head(titles_clean_clean, n=10)
```





```{r}
title_source <- VectorSource(titles_clean_clean$words)
title_corpus <- VCorpus(title_source)
```



```{r}
# this code section will take long (~3 min) to run. 
clean_corpus <- function(corpus){
  corpus <- tm_map(corpus, removePunctuation) # remove punctuation
  corpus <- tm_map(corpus, content_transformer(tolower)) # remove punctuation
  corpus <- tm_map(corpus, removeNumbers) # remove numbers
  corpus <- tm_map(corpus, removeWords, stopwords_en) # remove stop words
  corpus
}

title_corpus <- clean_corpus(title_corpus)
```



```{r}
title_dtm <- TermDocumentMatrix(title_corpus)
title_matrix <- as.matrix(title_dtm)
title_v <- sort(rowSums(title_matrix), decreasing=TRUE)
title_dt <- data.frame(word = names(title_v),freq=title_v)
```


```{r}
title_dt$word <- gsub("twofourd" , "2,4-D" , title_dt$word)
```


```{r}
title_dt %>% 
  filter(freq >= 10) %>% 
  ggplot(aes(x=reorder(word,freq), y=freq, fill=freq)) +
  scale_fill_continuous(low = "#FFF6F6", high = "#9b0000") +
  geom_col(show.legend=FALSE) + coord_flip() + theme_classic() +
  labs(y="Frequence (n)", x="Words") + #ylim(0,50) +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=13)) 
```
```{r}
words19 <- title_dt  %>% 
  select(word, freq) %>% 
  #group_by(word) %>% 
  add_tally(freq, name="nn") %>% 
  mutate(Perc=(freq/nn)*100) %>% 
  mutate_at(4, round, 1)  %>% 
  mutate(year = "2019") 
```



```{r message = FALSE, warning=FALSE} 
pal <- brewer.pal(8,"Dark2") #selecting the color palette

set.seed(1234)
wordcloud(words = title_dt$word, freq = title_dt$freq, min.freq=2, scale=c(4,.1),
           random.order=FALSE, rot.per=0.35, colors=pal)
```






```{r}
Data <- bind_rows(words02, words03, words04, words05, words06, words08, words09, words10, words11, words12, words13, words14, words15, words16, words17, words18, words19)
Data$year <- as.numeric(Data$year)
data <- Data %>% 
  filter( word == "palmer" | word == "glyphosate" |  word == "dicamba" | word == "resistant")
```




```{r warning = FALSE}
Data %>% 
    ggplot(aes(y=freq, label = word, size = word, color = word)) + 
      #geom_bar(stat ="identity", show.legend = FALSE) + 
      geom_text_wordcloud() +
#      scale_size_area(max_size = 20) +
      facet_wrap(~year) +
      ggsave("cloud.png", height=12, width = 12)
```

```{r}
Data %>% 
  #filter(year == "2005" | year == "2011") %>% 
ggplot(aes(freq/nn, fill = year)) +
  geom_histogram(show.legend = FALSE) +
  #xlim(NA, 0.0009) +
  facet_wrap(~year, ncol=4, scales = "free_y") +
  ggsave("figure.png")
```

```{r}
freq_by_rank <- Data %>% 
  group_by(year) %>% 
  mutate(rank = row_number(), 
         `term frequency` = freq/nn)

freq_by_rank
```
```{r}
freq_by_rank %>% 
  mutate(year = as.factor(year)) %>% 
  ggplot(aes(rank, `term frequency`, color = year)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
```

```{r}
rank_subset <- freq_by_rank %>% 
  filter(rank < 500,
         rank > 10)

lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)
```

```{r}
freq_by_rank %>%
  mutate(year = as.factor(year)) %>% 
  ggplot(aes(rank, `term frequency`, color = year)) + 
  geom_abline(intercept = -1.0868, slope = -0.8151, color = "gray50", linetype = 2) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
```

```{r}
year_words <- Data %>%
  filter
  bind_tf_idf(word, year, freq)

year_words
```

```{r}
year_words %>%
  select(-nn) %>%
  arrange(desc(tf_idf))
```



```{r}
year_words %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(year) %>% 
  top_n(15) %>% 
  ungroup() %>%
  ggplot(aes(reorder(word, tf_idf), tf_idf, fill = year)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~year, ncol = 4, scales = "free") +
  coord_flip() +
  ggsave("Figure 2.png", width = 12, height=12)
```


```{r}
data <- rbind(words02, words03, words04, words05)
year_words <- data %>%
  bind_tf_idf(word, year, freq)

year_words
```

```{r}
year_words %>%
  select(-nn) %>%
  arrange(desc(tf_idf))
```



```{r}
year_words %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(year) %>% 
  top_n(15) %>% 
  ungroup() %>%
  ggplot(aes(reorder(word, tf_idf), tf_idf, fill = year)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~year, ncol = 4, scales = "free") +
  coord_flip() +
  ggsave("Figure 2.png", width = 12, height=12)
```